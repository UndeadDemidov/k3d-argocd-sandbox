apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: vector
  finalizers:
    - resources-finalizer.argocd.argoproj.io
  labels:
    component: telemetry
spec:
  project: {{ .Values.project }}
  destination:
    name: "{{ .Values.cluster }}"
    namespace: {{ .Values.ns }}
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
  sources:
  - repoURL: https://helm.vector.dev
    chart: vector
    targetRevision: 0.50.0
    helm:
      valuesObject:
        role: Agent
        dataDir: /vector-data-dir
        resources: {}
        args:
          - -w
          - --config-dir
          - /etc/vector/
          - --log-format
          - json
        containerPorts:
          - name: metrics
            containerPort: 9598
            protocol: TCP
        service:
          enabled: false
        customConfig:
          data_dir: /vector-data-dir
          api:
            enabled: false
            address: 0.0.0.0:8686
            playground: true
          sources:
            k8s:
              type: kubernetes_logs
            vector_metrics:
              type: internal_metrics
              scrape_interval_secs: 60
          transforms:
            # 1. Нормализация: вытаскиваем k8s-поля, оставляем .message
            normalize:
              type: remap
              inputs: [k8s]
              source: |-
                .cluster = "{{ .Values.cluster }}"
                .env = "{{ .Values.cluster }}"

                .image = .kubernetes.container_image
                .container = .kubernetes.container_name
                .pod = .kubernetes.pod_name
                .ip = .kubernetes.pod_ip
                .namespace = .kubernetes.pod_namespace
                .node = .kubernetes.pod_node_name

                labels = .kubernetes.pod_labels
                if exists(labels."app.kubernetes.io/name") && !is_empty(string!(labels."app.kubernetes.io/name")) {
                  .app = string!(labels."app.kubernetes.io/name")
                } else if exists(labels."k8s-app") && !is_empty(string!(labels."k8s-app")) {
                  .app = string!(labels."k8s-app")
                } else if exists(labels."app") && !is_empty(string!(labels."app")) {
                  .app = string!(labels."app")
                } else if exists(labels."job-name") && !is_empty(string!(labels."job-name")) {
                  .app = string!(labels."job-name")
                }

                del(.file)
                del(.kubernetes)

            # 2. Детектор типа: json / logfmt / plain (по порядку, первый подходящий)
            # JSON: успешный parse_json и результат — объект или массив
            # logfmt: сообщение НАЧИНАЕТСЯ с key=value (не glog/klog с вкраплениями key=value в тексте)
            detect:
              type: remap
              inputs: [normalize]
              source: |-
                json_ok = starts_with(.message, "{") ?? false
                # logfmt: начинается с key=value или key="value"
                logfmt_ok = match(.message, r'^[^\s=]+=(?:"[^"]*"|\S+)') ?? false
                .log_format = if json_ok { "json" } else if logfmt_ok { "logfmt" } else { "plain" }

            # 3. Маршрутизация по типу (первый совпавший забирает событие)
            route_by_type:
              type: exclusive_route
              inputs: [detect]
              routes:
                - name: json
                  condition:
                    type: vrl
                    source: '.log_format == "json"'
                - name: logfmt
                  condition:
                    type: vrl
                    source: '.log_format == "logfmt"'

            # 3b. Plain: объединяем многострочные Java stack trace в одно событие (reduce)
            # Новое событие — когда строка НЕ продолжение (не "\t", не "  at ", не "Caused by:", не "Suppressed:")
            merge_plain_multiline:
              type: reduce
              inputs: [route_by_type._unmatched]
              group_by: [namespace, pod, container]
              merge_strategies:
                message: concat_newline
              starts_when:
                type: vrl
                source: |-
                  !(match(string!(.message), r'^\t') || match(string!(.message), r'^\s+at\s') || match(string!(.message), r'^Caused by:') || match(string!(.message), r'^Suppressed:'))
              expire_after_ms: 3000
              flush_period_ms: 500

            # 4a. Ветка JSON: парсим и собираем .log / .msg; при необходимости парсим вложенный JSON в .message
            parse_json:
              type: remap
              inputs: [route_by_type.json]
              source: |-
                .log = parse_json!(.message)

                if exists(.log.msg) {
                  .log.message = .log.msg
                  del(.log.msg)
                }

                if exists(.log."@version") {
                  .log.version = .log."@version"
                  del(.log."@version")
                  if exists(.log."@timestamp") {
                    .log.timestamp = .log."@timestamp"
                    del(.log."@timestamp")
                  }
                  if exists(.log."app-name") {
                    .log.app_name = .log."app-name"
                    del(.log."app-name")
                  }
                }

                .msg = encode_json(.log)
                if exists(.log.level) && .log.level != null && .log.level != "" { .level = .log.level }
                if exists(.log.level_value) {
                  v, err = to_string(.log.level_value)
                  if err == null {
                    .level = if v == "20000" { "info" } else if v == "10000" { "debug" } else if v == "30000" { "warn" } else if v == "40000" { "error" } else if v == "50000" { "fatal" } else if v == "5000" { "trace" } else { .level }
                  }
                }
                del(.message)

            # 4b. Ветка logfmt: parse_logfmt (logfmt key=value), потом .log / .msg
            parse_logfmt:
              type: remap
              inputs: [route_by_type.logfmt]
              source: |-
                .log = parse_logfmt!(.message)

                if exists(.log.msg) {
                  .log.message = .log.msg
                  del(.log.msg)
                }

                .msg = encode_json(.log)
                if exists(.log.level) && .log.level != null && .log.level != "" { .level = .log.level }
                del(.message)

            # 4c. Ветка plain: парсинг Java/Log4j (DD-Mon-YYYY HH:MM:SS.mmm LEVEL [thread] logger message),
            #     Kafka producer ([thread] LEVEL logger - message) или .msg в одну строку
            parse_plain:
              type: remap
              inputs: [merge_plain_multiline]
              source: |-
                .level = "unknown"
                # Java/Log4j: 05-Feb-2026 14:46:25.841 INFO [pool-4-thread-7] logger.name message text
                # Kafka: [kafka-producer-network-thread | producer-1] INFO com.farzoom.service.impl.KafkaMessageCallback - Message with UUID ... was send to topic ...
                # Gravitee: 00:17:30.929 [gio.sync-master1] [] ERROR i.g.g.services.sync.SyncManager - An error occurs while synchronizing organizations
                # Spring Boot: 2026-01-28 12:18:46.467  INFO 8 --- [nio-8080-exec-5] o.s...NativeEnvironmentRepository : Adding property source ...
                # Logback internal: 11:56:39,151 |-INFO in ch.qos.logback...@21c7208d - message (tag опционально в regex)
                .log = parse_klog(.message) ??
                      parse_nginx_log(.message, "combined") ??
                      parse_regex(.message, r'^(?P<timestamp>\d{2}-\w{3}-\d{4}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(?P<level>\w+)\s+\[(?P<thread>[^\]]+)\]\s+(?P<logger_name>[a-zA-Z0-9_.]+)\s+(?P<message>.*)$') ??
                      parse_regex(.message, r'^\[(?P<thread>[^\]]+)\]\s+(?P<level>\w+)\s+(?P<logger_name>[a-zA-Z0-9_.]+)\s+-\s+(?P<message>.*)$') ??
                      parse_regex(.message, r'^(?P<timestamp>\d{2}:\d{2}:\d{2}\.\d{3})\s+\[(?P<thread>[^\]]+)\](?:\s+\[(?P<context>[^\]]*)\])?\s+(?P<level>[A-Z]+)\s+(?P<logger_name>\S+)\s+-\s+(?P<message>.*)$') ??
                      parse_regex(.message, r'^(?P<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(?P<level>[A-Z]+)\s+(?P<pid>\d+)\s+---\s+\[(?P<thread>[^\]]+)\]\s+(?P<logger_name>[^:]+?)\s*:\s+(?P<message>.*)$') ??
                      parse_regex(.message, r'^(?P<timestamp>\d{1,2}:\d{2}:\d{2},\d{3})\s+\|\-(?P<level>\w+)\s+in\s+(?P<logger_name>[^\s]+?)(?:@(?P<tag>[0-9a-fA-F]+))?\s+-\s+(?P<message>.*)$') ??
                      null
                if exists(.log) && exists(.log.message) {
                  .level = downcase!(.log.level)
                  .msg = encode_json(.log)
                } else {
                  # Если лог содержит ".java:<число>)", то это stack trace
                  if match(.message, r'\.java:\d+\)') ?? false { 
                    .level = "error"
                    .stack_trace = "java"
                  }
                  .msg = .message
                  .log.message = .message
                  del(.message)
                }

          sinks:
            vlogs:
              type: elasticsearch
              inputs: [parse_json, parse_logfmt, parse_plain]
              endpoints:
                - http://vl-single-server.{{ .Values.ns }}.svc:9428/insert/elasticsearch/
              mode: bulk
              api_version: v8
              compression: gzip
              healthcheck:
                enabled: false
              request:
                headers:
                  VL-Time-Field: timestamp
                  VL-Stream-Fields: stream,cluster,env,node,namespace,app,pod,container,level
                  VL-Msg-Field: msg
                  AccountID: "0"
                  ProjectID: "0"
            vm:
              type: prometheus_exporter
              address: "0.0.0.0:9598"
              inputs:
              - vector_metrics

        extraObjects:
        - apiVersion: operator.victoriametrics.com/v1beta1
          kind: VMPodScrape
          metadata:
            name: vector
            namespace: {{ .Values.ns }}
          spec:
            jobLabel: app.kubernetes.io/name
            podMetricsEndpoints:
              - port: metrics
            namespaceSelector:
              matchNames:
                - {{ .Values.ns }}
            selector:
              matchLabels:
                app.kubernetes.io/instance: vector
                app.kubernetes.io/name: vector
